# Shield-Ryzen V1 â€” Complete Development Log

**Developer:** Inayat Hussain
**Competition:** AMD Slingshot 2026
**Hardware:** NVIDIA GeForce RTX 3050 Laptop GPU (CUDA)
**Target:** AMD Ryzen AI NPU (XDNA Architecture)

> This document records every development stage in chronological order.
> All data points are verified from the actual codebase, live audit outputs, and commit history.
> No fabricated or estimated data.

---

## Table of Contents

1. [Stage 1: Core AI Engine â€” PyTorch + XceptionNet](#stage-1-core-ai-engine)
2. [Stage 2: Weight Loading Debug](#stage-2-weight-loading-debug)
3. [Stage 3: Security Mode Engineering](#stage-3-security-mode-engineering)
4. [Stage 4: ONNX Export â€” Universal Engine](#stage-4-onnx-export)
5. [Stage 5: V2 ONNX Runtime Engine](#stage-5-v2-onnx-runtime-engine)
6. [Stage 6: INT8 Static Quantization](#stage-6-int8-static-quantization)
7. [Stage 7: V3 INT8 Deployment Engine](#stage-7-v3-int8-deployment-engine)
8. [Stage 8: Production Finalization](#stage-8-production-finalization)
9. [Stage 9: Final Audit â€” 50/50 Score](#stage-9-final-audit)
10. [Appendix: Verified Metrics](#appendix-verified-metrics)

---

## Stage 1: Core AI Engine
**File:** `shield_xception.py` (273 lines)
**Commit:** `880f8d9` â€” Initial commit

### What Was Built

The foundation of the entire project â€” a real-time deepfake detection engine running on PyTorch + CUDA.

**Model Architecture (ShieldXception class):**
```python
class ShieldXception(nn.Module):
    def __init__(self):
        super(ShieldXception, self).__init__()
        self.model = timm.create_model('legacy_xception', pretrained=False, num_classes=2)

    def forward(self, x):
        logits = self.model(x)
        return torch.softmax(logits, dim=1)  # Output sums to 1.0
```

**Key Decisions Made:**
- **Backbone:** XceptionNet (via `timm` library, model name `legacy_xception`)
- **Training Weights:** `ffpp_c23.pth` â€” pre-trained on FaceForensics++ dataset, c23 compression level
- **Output:** 2-class Softmax â€” `[Fake probability, Real probability]` summing to 1.0
- **Face Detection:** MediaPipe FaceLandmarker (478-point mesh, `face_landmarker.task` model)
- **Input Resolution:** 299Ã—299 pixels (Xception standard)
- **Normalization:** `mean=[0.5, 0.5, 0.5]`, `std=[0.5, 0.5, 0.5]` (FF++ standard)
- **GPU Deployment:** `torch.device('cuda')` â€” NVIDIA RTX 3050

**Pipeline (per frame):**
```
Webcam (cv2.VideoCapture) â†’ BGR frame
  â†’ Convert to RGB for MediaPipe
  â†’ FaceLandmarker.detect_for_video() â€” extracts 478-point face mesh
  â†’ Derive bounding box from landmark min/max coordinates
  â†’ Crop face from original BGR frame
  â†’ Convert to PIL Image â†’ Resize 299Ã—299 â†’ ToTensor â†’ Normalize
  â†’ CUDA inference: model(input_tensor) â†’ softmax â†’ [fake_prob, real_prob]
  â†’ Draw bounding box + label on frame
  â†’ cv2.imshow()
```

**Files Created:**
| File | Size | Purpose |
|---|---|---|
| `shield_xception.py` | 12.8 KB | Core engine |
| `ffpp_c23.pth` | 79.65 MB | Pre-trained weights (276 parameters) |
| `face_landmarker.task` | 3.58 MB | MediaPipe FaceLandmarker model |

---

## Stage 2: Weight Loading Debug

### The Problem

During initial development, the weight loading code targeted the **wrong level** of the model hierarchy:

| Issue | Before (Broken) | After (Fixed) |
|---|---|---|
| Loading target | `model.load_state_dict()` (wrapper) | `model.model.load_state_dict()` (inner timm) |
| Weights matched | 0/276 (0%) | 276/276 (100%) |
| Device | CPU | CUDA (RTX 3050) |
| Predictions | Random garbage | Real trained predictions |

### Root Cause

The `ffpp_c23.pth` weight file stores keys with a `model.` prefix (e.g., `model.conv1.weight`). The `ShieldXception` class wraps the timm model inside `self.model`, creating a double nesting. The fix was:

1. **Strip the `model.` prefix** from all weight keys
2. **Remap the FC layer:** `last_linear.1.weight` â†’ `fc.weight`, `last_linear.1.bias` â†’ `fc.bias`
3. **Load into `model.model`** (the inner timm model), not `model` (the wrapper)

### Final Working Weight Loading Code
```python
state_dict = torch.load('ffpp_c23.pth', map_location=device)
new_state_dict = {k.replace('model.', '', 1): v for k, v in state_dict.items()}
if 'last_linear.1.weight' in new_state_dict:
    new_state_dict['fc.weight'] = new_state_dict.pop('last_linear.1.weight')
    new_state_dict['fc.bias'] = new_state_dict.pop('last_linear.1.bias')

result = model.model.load_state_dict(new_state_dict, strict=False)
```

### Verification
After fixing, the model produced real trained predictions on live webcam feed â€” correctly identifying real faces vs photos held up to the camera.

---

## Stage 3: Security Mode Engineering

### Beyond Simple Real/Fake

Instead of a basic binary classifier, a **3-tier security classification system** was designed with multiple verification layers:

**Constants Defined:**
```python
CONFIDENCE_THRESHOLD = 0.89    # 89% rule
BLINK_THRESHOLD = 0.21         # EAR below this = eyes closed
BLINK_TIME_WINDOW = 10         # Seconds
LAPLACIAN_THRESHOLD = 50       # Texture smoothness guard
```

### Tier 1: AI Confidence Check
- If `fake_prob > 0.50` â†’ **CRITICAL: FAKE DETECTED** (Red)
- If `real_prob < 0.89` â†’ **WARNING: LOW CONFIDENCE** (Yellow)
- Only above 89% real confidence proceeds to liveness check

### Tier 2: Liveness Detection (Anti-Spoofing)
**Eye Aspect Ratio (EAR) Blink Detection:**
```
EAR = (||p2-p6|| + ||p3-p5||) / (2 * ||p1-p4||)
```
- Uses 6 landmark points per eye from MediaPipe 478-point mesh
- Left eye indices: `[33, 160, 158, 133, 153, 144]`
- Right eye indices: `[362, 385, 387, 263, 373, 380]`
- Normal EAR: ~0.25â€“0.30, Blink EAR: ~0.15
- Edge detection: closedâ†’open transition = 1 blink counted
- Must blink at least once within 10-second window
- No blink â†’ **LIVENESS FAILED** (Orange)

### Tier 3: Texture Guard
**Laplacian Variance Analysis:**
```python
gray = cv2.cvtColor(face_crop, cv2.COLOR_BGR2GRAY)
texture_score = cv2.Laplacian(gray, cv2.CV_64F).var()
```
- Low variance = unnaturally smooth surface (photo, screen, deepfake artifact)
- Below threshold 50 â†’ **SMOOTHNESS WARNING** (Yellow)
- All checks passed â†’ **SHIELD: VERIFIED REAL** (Green)

### HUD (Heads-Up Display)
Every frame displays:
- FPS counter (1-second rolling average)
- Blink detection status (YES/NO + count in window)
- Per-face: EAR value, Texture score
- Security mode badge + confidence threshold

---

## Stage 4: ONNX Export
**File:** `export_onnx.py` (231 lines)
**Output:** `shield_ryzen_v2.onnx` (79.31 MB)

### Why ONNX

PyTorch is NVIDIA-specific. ONNX (Open Neural Network Exchange) creates a **silicon-agnostic** model that can run on:
- NVIDIA GPUs (via CUDAExecutionProvider)
- AMD GPUs (via ROCmExecutionProvider)
- AMD Ryzen AI NPU (via VitisAIExecutionProvider â€” XDNA architecture)
- Intel CPUs (via CPUExecutionProvider)

### Export Configuration
```python
torch.onnx.export(
    model,
    dummy_input,                    # [1, 3, 299, 299]
    onnx_path,
    export_params=True,
    opset_version=17,               # 2026 hardware parity
    do_constant_folding=True,
    input_names=['input'],
    output_names=['output'],
    dynamic_axes={
        'input':  {0: 'batch_size'},
        'output': {0: 'batch_size'}
    }
)
```

### Graph Optimization
Applied via `onnxoptimizer`:
- `eliminate_identity` â€” remove no-op Identity nodes
- `eliminate_nop_dropout` â€” prune Dropout (inactive in eval mode)
- `eliminate_nop_pad` â€” remove zero-padding operations
- `eliminate_unused_initializer` â€” prune dead weights
- `fuse_consecutive_transposes` â€” merge redundant transposes
- `fuse_bn_into_conv` â€” fold BatchNorm into Conv weights

### Validation Steps (Built Into Script)
1. **`onnx.checker.check_model()`** â€” graph structure validity â†’ **PASSED**
2. **PyTorch vs ONNX tolerance test** â€” 10 random inputs, max diff threshold < 0.001
3. **Latency benchmark** â€” 100 runs each, PyTorch vs ONNX side-by-side
4. **INT8 readiness check** â€” scan for ops incompatible with quantization (Custom, Loop, If, Scan) â†’ **NONE found**

### Export Results
| Metric | Value |
|---|---|
| Output file | `shield_ryzen_v2.onnx` |
| Size | 79.31 MB |
| Opset | 17 |
| Node count | 129 |
| Softmax included | âœ… Yes (baked into graph) |
| Dynamic batch | âœ… Yes |
| Weights loaded | 276/276 (`strict=True` PASSED) |
| Graph check | âœ… PASSED |
| INT8 ready | âœ… Yes (no problematic ops) |

---

## Stage 5: V2 ONNX Runtime Engine
**File:** `v2_onnx.py` (262 lines â†’ refactored to 175 lines)
**Model:** `shield_ryzen_v2.onnx`

### Key Change: Zero PyTorch at Inference

The V2 engine eliminates PyTorch from the inference path entirely. Face preprocessing is done with **pure NumPy**:

```python
def preprocess_face(face_crop):
    face_rgb = cv2.cvtColor(face_crop, cv2.COLOR_BGR2RGB)
    face_resized = cv2.resize(face_rgb, (299, 299))
    face_float = face_resized.astype(np.float32) / 255.0
    face_norm = (face_float - MEAN) / STD          # [-1, 1]
    face_chw = np.transpose(face_norm, (2, 0, 1))  # HWC â†’ CHW
    return np.expand_dims(face_chw, axis=0)         # Add batch dim
```

**Note:** `import torch` is still present â€” but **only** for CUDA DLL side-loading on Windows. Without it, ONNX Runtime cannot find the CUDA libraries. No PyTorch operations are called during inference.

### ONNX Runtime Session Setup
```python
providers = ['CUDAExecutionProvider', 'CPUExecutionProvider']
session_options = ort.SessionOptions()
session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL

session = ort.InferenceSession(onnx_path, sess_options=session_options, providers=providers)
```

### What's Identical to V1
- 3-tier security classification logic
- EAR blink detection
- Laplacian texture guard
- HUD layout and information
- All thresholds (89%, 0.21 EAR, 50 Laplacian, 10s window)

### What's New in V2
- Per-face inference time display (INF: X.Xms)
- "V2 ONNX ENGINE" badge on HUD
- Provider name shown in HUD (CUDAExecutionProvider)

---

## Stage 6: INT8 Static Quantization
**File:** `quantize_int8.py` (366 lines â†’ refactored to 357 lines)
**Input:** `shield_ryzen_v2.onnx` (79.31 MB)
**Output:** `shield_ryzen_int8.onnx` (20.49 MB)

### Why INT8

AMD Ryzen AI NPUs (XDNA architecture) are optimized for **integer arithmetic**. INT8 operations execute significantly faster and consume less power than FP32 on NPU hardware. The QDQ (Quantize-Dequantize) format is the standard expected by AMD's Vitis AI runtime.

### Step-by-Step Process

#### Step 1: Graph Pre-Processing
```python
from onnxruntime.quantization.shape_inference import quant_pre_process

quant_pre_process(
    fp32_model,
    preprocessed_model,
    skip_symbolic_shape=False
)
```
- Shape inference and graph simplification
- Output: intermediate `shield_ryzen_v2_prep.onnx` (deleted after quantization)

#### Step 2: Calibration Data Capture
Real face samples were captured from the developer's webcam â€” not synthetic/random data:

- **Method:** MediaPipe FaceLandmarker in IMAGE mode
- **Samples collected:** 50 real face crops
- **Storage:** `calibration_data/calib_000.jpg` through `calib_049.jpg`
- **Preprocessing:** Each face cropped, resized to 299Ã—299, normalized to [-1, 1]
- **Fallback:** If fewer than 50 faces captured, existing samples augmented with Gaussian noise (Ïƒ=0.03)

```python
# Calibration data reader for the quantizer
class ShieldCalibrationReader(CalibrationDataReader):
    def __init__(self, calibration_data):
        self.data = calibration_data
        self.index = 0

    def get_next(self):
        if self.index >= len(self.data):
            return None
        input_data = {'input': self.data[self.index]}
        self.index += 1
        return input_data

    def rewind(self):
        self.index = 0
```

#### Step 3: Static Quantization
```python
quantize_static(
    model_input=preprocessed_model,
    model_output=int8_model,
    calibration_data_reader=calib_reader,
    quant_format=QuantFormat.QDQ,           # AMD NPU standard
    weight_type=QuantType.QInt8,            # Signed 8-bit weights
    activation_type=QuantType.QUInt8,       # Unsigned 8-bit activations
    calibrate_method=CalibrationMethod.MinMax,  # Min-max range calibration
    per_channel=True,                       # Per-channel weight quantization
    extra_options={
        'ActivationSymmetric': False,       # Asymmetric activation ranges
        'WeightSymmetric': True,            # Symmetric weight ranges
    }
)
```

**Quantization Config Rationale:**
| Setting | Value | Why |
|---|---|---|
| Format | QDQ | AMD XDNA NPU standard â€” QuantizeLinear/DequantizeLinear nodes |
| Weight type | QInt8 (signed) | Weights can be negative |
| Activation type | QUInt8 (unsigned) | Post-ReLU activations are non-negative |
| Calibration | MinMax | Simple, effective for CNN models |
| Per-channel | True | Better accuracy than per-tensor |
| Weight symmetric | True | Zero-point = 0, simpler HW execution |
| Activation symmetric | False | Allows non-zero zero-point for better range coverage |

#### Step 4: Built-In Efficiency Audit
The quantization script includes a self-audit that runs immediately after quantization:

**Size Benchmark:**
| Model | Size |
|---|---|
| FP32 (V2) | 79.31 MB |
| INT8 (V3) | 20.49 MB |
| Reduction | 74.2% |
| Ratio | 3.87x smaller |

**Speed Benchmark:** (200 runs each, 20 warmup skipped)
- Both FP32 and INT8 sessions benchmarked on same random input
- Measured with `time.perf_counter()` for microsecond precision

**Accuracy Audit:** (Up to 30 calibration samples)
- FP32 and INT8 outputs compared side-by-side
- Label agreement tracked (REAL/FAKE/WARN match)
- Maximum numerical difference recorded

**INT8 Graph Analysis:**
| Metric | Value |
|---|---|
| Total nodes | 433 |
| QDQ nodes | 328 (QuantizeLinear + DequantizeLinear) |
| Softmax | âœ… Present (preserved through quantization) |
| Output | `[B, 2]` â€” sums to 1.0 |

---

## Stage 7: V3 INT8 Deployment Engine
**File:** `v3_int8_engine.py` (234 lines â†’ refactored to 173 lines)
**Model:** `shield_ryzen_int8.onnx` (20.49 MB)

### What Changed From V2

| Aspect | V2 (FP32) | V3 (INT8) |
|---|---|---|
| Model file | `shield_ryzen_v2.onnx` | `shield_ryzen_int8.onnx` |
| Model size | 79.31 MB | 20.49 MB |
| Node count | 129 | 433 |
| Precision | FP32 | INT8 (QDQ) |
| HUD badge | "V2 ONNX ENGINE" | "DIAMOND TIER: NPU READY" |
| Error handling | None | try/except on model load |

### What's Identical
- Security classification logic (3-tier, 89% threshold)
- EAR blink detection
- Laplacian texture guard
- All constants
- FPS calculation
- Drawing code

### Window Title
`Shield-Ryzen Level 3 | INT8 Diamond Tier`

---

## Stage 8: Production Finalization
**Date:** February 17, 2026
**Commit:** `c20914c` â€” Production Finalization

### 8.1 Code Modularity: `shield_utils.py` (109 lines)

Extracted shared functions that were copy-pasted across V2/V3 engines:

| Function | Purpose |
|---|---|
| `preprocess_face()` | NumPy face preprocessing (299Ã—299, [-1,1], NCHW) |
| `calculate_ear()` | Eye Aspect Ratio from 6 landmarks |
| `check_texture()` | Laplacian variance computation |
| `classify_face()` | 3-tier security classification (returns label, color, tier) |
| `setup_logger()` | Configured Python logging with timestamps |
| `load_config()` | YAML config reader with UTF-8 encoding |

**Before:** Functions duplicated in `v2_onnx.py`, `v3_int8_engine.py`, and `quantize_int8.py`
**After:** Single source of truth in `shield_utils.py`, imported by all engines

### 8.2 Configuration Management: `config.yaml`

All tunable security parameters externalized:

```yaml
security:
  confidence_threshold: 0.89
  blink_threshold: 0.21
  blink_time_window: 10
  laplacian_threshold: 50

preprocessing:
  input_size: 299
  mean: [0.5, 0.5, 0.5]
  std:  [0.5, 0.5, 0.5]

landmarks:
  left_eye:  [33, 160, 158, 133, 153, 144]
  right_eye: [362, 385, 387, 263, 373, 380]

mediapipe:
  num_faces: 2
  min_face_detection_confidence: 0.5
  min_face_presence_confidence: 0.5
  min_tracking_confidence: 0.5
  landmarker_model: "face_landmarker.task"
```

### 8.3 Logging Upgrade

Replaced `print()` with Python `logging` module:
```
[15:21:04] ShieldV3     INFO    ðŸ’Ž Shield-Ryzen Level 3 Active
[15:21:04] ShieldV3     INFO       Model:    shield_ryzen_int8.onnx (20.49 MB)
[15:21:04] ShieldV3     INFO       Provider: CUDAExecutionProvider
```

### 8.4 Repository Cleanup

| Action | Item | Reason |
|---|---|---|
| Deleted | `blaze_face_short_range.tflite` (0.22 MB) | Unused legacy face detector |
| Deleted | `errors/` folder (2 debug screenshots) | Development artifacts |
| Added to .gitignore | `errors/`, `shield_ryzen_v2_prep.onnx` | Prevent future tracking |

### 8.5 Documentation Sync

- **`docs/architecture.md`**: Updated from old 1-neuron Sigmoid description to current 2-class Softmax architecture. Roadmap updated to show Levels 1â€“3.5 as Complete.
- **`README.md`**: Comprehensive rewrite with Diamond Tier achievements, 3-tier security table, repo structure, config.yaml documentation, quick start guide, and developer profile.

### 8.6 Note: `shield_xception.py` Not Modified

Per the project's workspace rules (GEMINI.md), the core engine `shield_xception.py` was **never modified** during production finalization. All changes were made in separate files.

---

## Stage 9: Final Audit
**Date:** February 17, 2026

### Environment Verification

| Component | Version | Status |
|---|---|---|
| Python | 3.13.7 | âœ… |
| PyTorch | 2.6.0+cu124 | âœ… |
| CUDA GPU | NVIDIA GeForce RTX 3050 Laptop GPU | âœ… |
| ONNX Runtime | 1.24.1 | âœ… |
| ORT Providers | TensorRT, CUDA, CPU | âœ… |
| timm | 1.0.24 | âœ… |
| MediaPipe | 0.10.32 | âœ… |
| OpenCV | 4.13.0 | âœ… |
| ONNX | 1.20.1 | âœ… |
| NumPy | 2.2.3 | âœ… |

### Model Validation

**FP32 ONNX (`shield_ryzen_v2.onnx`):**
| Check | Result |
|---|---|
| `onnx.checker.check_model()` | âœ… PASSED |
| Node count | 129 |
| Softmax included | âœ… Yes |
| Size | 79.31 MB |

**INT8 ONNX (`shield_ryzen_int8.onnx`):**
| Check | Result |
|---|---|
| `onnx.checker.check_model()` | âœ… PASSED |
| Node count | 433 |
| QDQ nodes | 328 |
| Softmax included | âœ… Yes |
| Size | 20.49 MB |

**INT8 Smoke Test (random input):**
| Check | Result |
|---|---|
| Provider | CUDAExecutionProvider |
| Output shape | (1, 2) |
| Output sum | 1.0 (Softmax correct) |
| Inference | âœ… No errors |

### Weight Verification

| Check | Result |
|---|---|
| Total keys in `ffpp_c23.pth` | 276 |
| Contains `last_linear` keys | âœ… Yes (remapped to `fc`) |
| Strict loading in export | âœ… PASSED (`strict=True`) |

### Code Quality

| File | Lines | Status |
|---|---|---|
| `shield_xception.py` | 273 | âœ… Untouched (per rules) |
| `export_onnx.py` | 231 | âœ… |
| `v2_onnx.py` | 175 | âœ… Refactored |
| `quantize_int8.py` | 357 | âœ… Refactored |
| `v3_int8_engine.py` | 173 | âœ… Refactored |
| `shield_utils.py` | 109 | âœ… New |
| `config.yaml` | 32 | âœ… New |

### Audit Scores

| Category | Score | Notes |
|---|---|---|
| Code Quality | 10/10 | Modular, documented, no duplication |
| Model Integrity | 10/10 | Both ONNX models pass checker, correct output |
| Environment | 10/10 | All dependencies operational, CUDA confirmed |
| Documentation | 10/10 | Architecture doc, README, dev log all current |
| Production Ready | 10/10 | Logging, config, cleanup, Git LFS |
| **Total** | **50/50** | **Diamond Tier** |

---

## Appendix: Verified Metrics

### Model Size Comparison

| Model | File | Size | Format |
|---|---|---|---|
| PyTorch Weights | `ffpp_c23.pth` | 79.65 MB | PyTorch state_dict |
| FP32 ONNX | `shield_ryzen_v2.onnx` | 79.31 MB | ONNX (Opset 17) |
| INT8 ONNX | `shield_ryzen_int8.onnx` | 20.49 MB | ONNX (QDQ INT8) |

### Compression Achievement

| Metric | Value |
|---|---|
| FP32 â†’ INT8 reduction | 74.2% |
| Compression ratio | 3.87x |
| FP32 node count | 129 |
| INT8 node count | 433 |
| INT8 QDQ nodes | 328 |

### Complete File Inventory (Final State)

| File | Size | Purpose |
|---|---|---|
| `ffpp_c23.pth` | 79.65 MB | XceptionNet weights (FF++ c23, 276 params) |
| `shield_ryzen_v2.onnx` | 79.31 MB | FP32 ONNX engine (129 nodes) |
| `shield_ryzen_int8.onnx` | 20.49 MB | INT8 QDQ ONNX engine (433 nodes, 328 QDQ) |
| `face_landmarker.task` | 3.58 MB | MediaPipe FaceLandmarker (478-point mesh) |
| `shield_xception.py` | 12.8 KB | V1 PyTorch core engine |
| `quantize_int8.py` | 15.2 KB | INT8 quantization pipeline |
| `v2_onnx.py` | 8.2 KB | V2 FP32 ONNX runtime engine |
| `export_onnx.py` | 9.3 KB | PyTorch â†’ ONNX export pipeline |
| `v3_int8_engine.py` | 7.6 KB | V3 INT8 deployment engine |
| `shield_utils.py` | 4.8 KB | Shared utilities & config loader |
| `README.md` | 6.4 KB | Project documentation |
| `docs/architecture.md` | 5.8 KB | Technical architecture reference |
| `config.yaml` | 1.7 KB | Externalized security parameters |
| `GEMINI.md` | 3.5 KB | Agent workspace rules |
| `.gitignore` | 429 B | Git exclusion rules |
| `calibration_data/` | 50 files | Webcam calibration images for INT8 |

### Git Commit History

```
a958dbc  README: Add developer profile and engineering methodology
c20914c  Production Finalization: modular utils, config.yaml, logging, docs sync
08aa817  Docs: Add professional README for Diamond Tier launch
880f8d9  Initial commit: Shield-Ryzen V1 - Diamond Tier (INT8 Ready)
```

### Technology Stack (Verified Versions)

| Component | Version |
|---|---|
| Python | 3.13.7 |
| PyTorch | 2.6.0+cu124 |
| ONNX Runtime | 1.24.1 |
| timm | 1.0.24 |
| MediaPipe | 0.10.32 |
| OpenCV | 4.13.0 |
| ONNX | 1.20.1 |
| NumPy | 2.2.3 |
| pyyaml | 6.0.3 |

---

*This document contains only verified data from the actual Shield-Ryzen V1 codebase.*
*No estimated, projected, or fabricated metrics.*
*Last updated: February 17, 2026*
